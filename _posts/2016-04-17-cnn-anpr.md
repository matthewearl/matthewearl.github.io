---
layout: default
title: Number plate recognition with Tensorflow
thumbimage: /assets/inverse-haar/feature1.png
excerpt:
---

{% include post-title.html %}

## Introduction

Over the past few weeks I've been dabbling with deep learning,
in particular [convolutional neural networks](https://
en.wikipedia.org/wiki/Convolutional_neural_network). One standout paper from
recent times is Google's
[Multi-digit Number Recognition from Street View](http://
static.googleusercontent.com/media/research.google.com/en//pubs/archive/
42241.pdf). This paper describes a system for extracting house numbers from
street view imagery using little more than a single neural network. The
authors then go on to explain how the same network can be applied to breaking
Google's own CAPTCHA system with human-level accuracy.

In order to get some hands-on experience with implementing neural networks I
decided I'd design a system to solve a similar problem: Automated number plate
recognition (automated license plate recognition if you're in the US). My
reasons for doing this are three-fold:

* I should be able to use the same (or a similar) network topology as the
  Google paper: The Google topology was shown to work equally well at solving
  CAPTCHAs, as such it's reasonable to assume that it'd perform well on reading
  number plates too. Having a known-good network topology will greatly simplify
  things as I learn the ropes of CNNs.

* I can easily generate training data. One of the major issues with training
  neural networks is the requirement for lots of labelled training data.
  Hundreds of thousands of labelled training images are often required to
  properly train a network. Fortunately, the relevant uniformity of UK number
  plates means I can synthesize training data.

* Curiosity. Traditional ANPR systems [have relied on](https://en.wikipedia.org/wiki/ Automatic_number_plate_recognition#Algorithms) hand-written algorithms for plate localization,
  normalization, segmentation, character recognition etc. As such these systems
  tend to be many thousands of lines long. It'd be interesting to see how good
  a system I can develop with minimal domain-specific knowledge with a
  relatively small amount of code.

For this project I've used [TensorFlow](https://www.tensorflow.org/), Python,
OpenCV and NumPy.

## Windowing

In order to simplify training image generation and to reduce computational
requirements I decided my network would operate on 128x64 grayscale input
images. In terms of outputs the network should indicate:

* The probability a number plate is present in the input image. 

* The probability of the digit in each position, ie. for each of the 7 possible
  it should return a probability distribution across the 36 possible
  characters. (For this project I assume number plates have exactly 7
  characters, as is the case with most UK number plates).

128x64 was chosen as the input resolution as this is small enough to permit
training in a reasonable amount of time with modest resources, but
also large enough for number plates to be somewhat readable:

{% include img.html src="/assets/cnn-anpr/window-example.jpg" alt="Window" %}

<sup>[Image credit](#image_credits)</sup>

In order to detect number plates in larger images, a sliding window approach is
used, at various scales:

{% include img.html src="/assets/cnn-anpr/window-scan.gif" alt="Scan" %}

<sup>[Image credit](#image_credits)</sup>

The image on the right is the 128x64 input that the neural net sees, whereas
the left shows the window in the context of the original input image.  The
colour of the box indicates whether the network should detect a number plate
there.  We wish for the network to indicate a number plate is present iff:

* The plate falls entirely within the image bounds.

* The plate's width is less than 80% of the images width, and the plate's
  height is less than 87.5% of the image's height.

* The plate's width is greater than 60% of the image's width or the plate's
  height is greater than 60% of the image's height.

With these numbers we can use a sliding window that moves 8 pixels at a time,
and zooms in $$ \sqrt[](2) $$ times between zoom levels and be guaranteed not
to miss any plates, while at the same time not generating an excessive number
of matches for any single plate.

## Synthesizing images

To train any neural net, a set of training data along with correct outputs must
be provided. In this case, this will be a set of 128x64 images (along with the
expected output). Here's an illustrative sample:

* ![Training image](/assets/cnn-anpr/00000117_HH41RFP_1.png) expected output 
  `HH41RFP 1`.
* ![Training image](/assets/cnn-anpr/00000118_FB78PFD_1.png) expected output
  `FB78PFD 1`.
* ![Training image](/assets/cnn-anpr/00000121_JW01GAI_0.png) expected output
  `JW01GAI 0`. (Plate partially truncated.)
* ![Training image](/assets/cnn-anpr/00000129_AM46KVG_0.png) expected output
  `AM46KVG 0`. (Plate too small.)
* ![Training image](/assets/cnn-anpr/00000138_XG86KIO_0.png) expected output
  `XG86KIO 0`. (Plate too big.)
* ![Training image](/assets/cnn-anpr/00000164_XH07NYO_0.png) expected output
  `XH07NYO 0`. (Plate not present at all.)

The first part of the expected output is the number the net should output. The
second part is the "presence" value that the net should ouput. For data
labelled as not present I've included an explanation in brackets.

The process for generating the images is illustrated below:

{% include img.html src="/assets/cnn-anpr/pipeline.svg" alt="Pipeline" %}

The text and plate colour are chosen randomly. Noise is added at the end to
avoid the network depending too much on sharply defined edges, as these may not
be present in real world images.

Having a background is important as it means the network must learn to identify
the bounds of the number plate without "cheating":  Were a black background
used, for example, the network may learn to identify plate location based on
non-blackness, which would clearly not work with real pictures of cars. 

The backgrounds are sourced from the [SUN database](http://
vision.cs.princeton.edu/projects/2010/SUN/), which contains over 100,000
images. Its important the number of images is large to avoid the network
"memorizing" background images.

The transformation applied to the plate (and its mask) is an affine
transformation based on a random roll, pitch, yaw, translation, and scale.
The range allowed for each parameter was selected according to the ranges that
number plates are likely to be seen. For example, yaw is allowed to vary a lot
more than roll (you're more likely to see a car turning a corner, than on its
side).

The code to do all this is relatively short (~300 lines).  It can be read in
`gen.py` @@@ add link.

## The network

Here's the network topology used:

{% include img.html src="/assets/cnn-anpr/topology.svg" alt="Topology" %}

It is in fact based on [this paper](https://vision.in.tum.de/_media/spezial/
bib/stark-gcpr15.pdf) by Stark et al, as it gives more specifics about the
topology used than the Google paper.  The difference is my input image is of a
different aspect ratio, so I've fiddled with the pooling sizes to make things
fit.

The output layer has one node (shown on the left) which is used as the presence
indicator.  The rest encode the probability of a particular number plate: Each
column as shown in the diagram corresponds with one of the digits in the number
plate, and each node gives the probability of the corresponding character being
present. For example, the node in column 2 row 3 gives the probability that the
second digit is a `C`.

As is standard with deep neural nets, all but the output layers use [ReLU
activation](https://en.wikipedia.org/wiki/Rectifier_(neural_networks)). The
presence node has sigmoid activation whereas the other nodes use softmax across
characters (ie. so that the probability in each column sums to one).

The code defining the network is in `model.py`. @@@ add link

The loss function is defined in terms of the cross-entropy between the label
and the network output. For numerical stability the activation functions of the
final layer are rolled into the cross-entropy calculation, using
[`softmax_cross_entropy_with_logits`](https://www.tensorflow.org/versions/
r0.8/api_docs/python/nn.html#softmax_cross_entropy_with_logits) and
[`sigmoid_cross_entropy_with_logits`](https://www.tensorflow.org/versions/
r0.8/api_docs/python/nn.html#sigmoid_cross_entropy_with_logits).

Training (`train.py` @@@ add link) takes about 6 hours using a nVidia GTX 970,
with training data being generated on-the-fly by a background process on the
CPU.

## Output Processing

To actually detect and recognize number plates in an input image, a network
much like the above is applied to 128x64 windows at various positions and
scales, as described in the windowing section.

The network differs from the one used in training in that the last two layers
are convolutional rather than fully connected, and the input image can be any
size rather than 128x64. The idea is that the whole image at a particular scale
can be fed into this network which yields an image with a presence / character
probability vector for each "pixel".

Visualizing the "presence" portion of the output yields something like the
following:

{% include img.html src="/assets/cnn-anpr/out-many.jpg" alt="Out unfiltered" %}

<sup>[Image credit](#image_credits)</sup>

The boxes here are regions where the network detects a greater than 99%
probability that a number plate being present. The reason for the high
threshold is to account for the prior probability of a plate being present
being much lower than suggested by the training: During training roughly half
of the input images contained a plate.

To cope with the obvious duplicates, we apply a form of non-maximum suppression
to the output:

{% include img.html src="/assets/cnn-anpr/out.jpg" alt="Out" %}

<sup>[Image credit](#image_credits)</sup>

The technique used here first groups the rectangles into overlapping
rectangles, and for each group outputs:

* The intersection of all the bounding boxes.
* The license number corresponding with the box in the group that had the
  highest probability of being present.

## Conclusion


## Image Credits

[Original "Proton Saga EV" image](https://commons.wikimedia.org/wiki/
File:Proton_Saga_EV_at_the_RAC_Future_Car_Challenge_2011,_U.K.jpg) by
[Somaditya Bandyopadhyay](http://www.flickr.com/people/16836099@N08/) licensed
under the
[Creative Commons Attribution-Share Alike 2.0 Generic license](https://
creativecommons.org/licenses/by-sa/2.0/deed.en).

[Original "Google Street View Car" image](https://commons.wikimedia.org/wiki/
File:Google_Street_View_Car_near_Howden,_UK_2.JPG) by [Reedy](https://
commons.wikimedia.org/wiki/User:Reedy] licensed under the
[Creative Commons Attribution-Share Alike 3.0 Unported license](https://
creativecommons.org/licenses/by-sa/3.0/deed.en).

