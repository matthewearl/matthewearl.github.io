---
layout: default
title: Number plate recognition with Tensorflow
thumbimage: /assets/inverse-haar/feature1.png
excerpt:
---

{% include post-title.html %}

## Introduction

Over the past few months I've been teaching myself about machine learning, 
in particular [convolutional neural networks](https://
en.wikipedia.org/wiki/Convolutional_neural_network). One standout paper from
recent times is Google's
[Multi-digit Number Recognition from Street View](http://
static.googleusercontent.com/media/research.google.com/en//pubs/archive/
42241.pdf). This paper describes how the team successfully designed a system
for extracting house numbers from Street view imagery, by more-or-less
shoving labelled house number pictures into a (carefully chosen) neural
network.

In order to get some hands-on experience with implementing neural networks I
decided I'd design a system to solve a similar problem: Automated number plate
recognition (automated license plate recognition if you're in the US). My
reasons for doing this are two-fold:

* I should be able to use the same (or a similar) network topology as the
  Google paper: The Google topology was shown to work equally well at solving
  CAPTCHAs, as such it's reasonable to assume that it'd perform well on reading
  number plates too. Having a known-good network topology will greatly simplify
  things as I learn the ropes of CNNs.

* I can easily generate training data. One of the major issues with training
  neural networks is the requirement for lots of labelled training data.
  Hundreds of thousands of labelled training images are often required to
  properly train a network. Fortunately, the relevant uniformity of UK number
  plates means I can synthesize training data.

For this project I've used [TensorFlow](https://www.tensorflow.org/), Python,
OpenCV and NumPy.

## Windowing

In order to simplify training image generation, and to reduce computational
requirements I decided my network would operate on 128x64 grayscale input
images. The network should indicate:

* Whether a number plate is present in the input image. 

* The likelihood of the digit in each position. (For the purposes of this
  project I assume a fixed 7 digits, as is the case with most UK cars).

The reason for using 128x64 is this is about as small as one can go without
compromising readability while allowing for some variation in scale:

{% include img.html src="/assets/cnn-anpr/window-example.jpg" alt="Window" %}

In order to detect number plates a sliding window approach is used, at various
scales:

{% include img.html src="/assets/cnn-anpr/window-scan.gif" alt="Scan" %}

The image on the right is the 128x64 input that the neural net sees, whereas
the left shows the window in the context of the original input image.  The
colour of the box indicates whether the network should detect a number plate
there.  We wish for the network to indicate a number plate is present iff:

* The plate falls entirely within the image bounds.

* The plate's width is less than 80% of the images width, and the plate's
  height is less than 87.5% of the image's height.

* The plate's width is greater than 60% of the image's width or the plate's
  height is greater than 60% of the image's height.

With these numbers we can use a sliding window that moves 8 pixels at a time,
and zooms in $$ \sqrt[](2) $$ times between zoom levels and be guaranteed not
to miss any plates, while at the same time not generating an excessive number
of matches for any single plate.

## Synthesizing images

In order to train any neural net, a set of training data along with correct
outputs must be provided. In this case, this will be a set of 128x64 images
and expected output. Here's an illustrative sample:

* ![Training image](/assets/cnn-anpr/00000117_HH41RFP_1.png) expected output 
  `HH41RFP 1`.
* ![Training image](/assets/cnn-anpr/00000118_FB78PFD_1.png) expected output
  `FB78PFD 1`.
* ![Training image](/assets/cnn-anpr/00000121_JW01GAI_0.png) expected output
  `JW01GAI 0`. (Plate partially truncated.)
* ![Training image](/assets/cnn-anpr/00000129_AM46KVG_0.png) expected output
  `AM46KVG 0`. (Plate too small.)
* ![Training image](/assets/cnn-anpr/00000138_XG86KIO_0.png) expected output
  `XG86KIO 0`. (Plate too big.)
* ![Training image](/assets/cnn-anpr/00000164_XH07NYO_0.png) expected output
  `XH07NYO 0`. (Plate not present at all.)

The first part of the expected output is the number the net should output. The
second part is the "presence" value that the net should ouput. For data
labelled as not present I've included an explanation in brackets.

The process for generating the images is illustrated below:

{% include img.html src="/assets/cnn-anpr/pipeline.svg" alt="Pipeline" %}

The text and plate colour are chosen randomly. Noise is added at the end to
avoid the network depending too much on sharply defined edges, as these may not
be present in real world images.

Having a background is important as it means the network must learn to identify
the bounds of the number plate without "cheating":  Were a black background
used, for example, the network may learn to identify plate location based on
non-blackness, which would clearly not work with real pictures of cars. 

The backgrounds are sourced from the [SUN database](http://
vision.cs.princeton.edu/projects/2010/SUN/), which contains over 100,000
images. Its important the number of images is large to avoid the network
"memorizing" background images.

The transformation applied to the plate (and its mask) is an affine
transformation based on a random roll, pitch, yaw, translation, and scale.
The range allowed for each parameter was selected according to the ranges that
number plates are likely to be seen. For example, yaw is allowed to vary a lot
more than roll (you're more likely to see a car turning a corner, than on its
side).

The code to do all this is relatively short (~300 lines).  It can be read in
`gen.py` @@@ add link.

## The network



## Output Processing

## Conclusion

